{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Selamat datang dihalaman tugas Penambangan Data \u00b6 Nama : Lailatul Badria D.A.A Nim : 180411100149 Kelas : Penambangan Data-5B Jurusan : Teknik Informatika Angkatan : 2018 Perguruan Tinggi : Universitas Trunojoyo Madura","title":"Index"},{"location":"#selamat-datang-dihalaman-tugas-penambangan-data","text":"Nama : Lailatul Badria D.A.A Nim : 180411100149 Kelas : Penambangan Data-5B Jurusan : Teknik Informatika Angkatan : 2018 Perguruan Tinggi : Universitas Trunojoyo Madura","title":"Selamat datang dihalaman tugas Penambangan Data"},{"location":"jrak/","text":"Mengukur Jarak Data \u00b6 Mengukur Jarak Tipe Numerik \u00b6 Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkanSebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaitu v1,v2v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn,v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yixi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya Minkowski Distance \u00b6 Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Manhattan distance \u00b6 Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ Euclidean distance \u00b6 Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini. Average Distance \u00b6 Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik x,y dalam ruang dimensi n, rata-rata jarak didefinisikan dengan $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ Weighted euclidean distance \u00b6 Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ Chord distance \u00b6 Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ $$ dimana | x | {2} adalah L^{2} \\text {-norm} | x | {2} = \\sqrt { \\sum_{ i = 1 }^{ n }x_{i}^{2}} $$ Mahalanobis distance \u00b6 Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ Tugas II Mengukur Jarak Data \u00b6 from scipy import stats import numpy as np import seaborn as sns import matplotlib.pyplot as plt import pandas as pd df = pd . read_csv ( 'data2.csv' , sep = \";\" ) k = df . iloc [ 10 : 17 ] k .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age of patient at time of operation Patient's year of operation Number of positive axillary nodes detected Unnamed: 3 10 34 60 1 1 11 34 61 10 1 12 34 67 7 1 13 34 60 0 1 14 35 64 13 1 15 35 63 0 1 16 36 60 1 1 numerical = [ 0 , 3 ] categorical = [ 1 , 2 , 6 , 7 ] binary = [ 4 , 5 , 8 ] ordinal = [ 1 , 2 ] from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v1-v3\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v2-v3\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v3-v4\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v4-v5\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v5-v6\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' ))) Data Jarak Numeric Ordinal Categorical Binary v1-v2 0 0 0 0 0 v1-v3 0 0 0 0 0 v2-v3 0 0 0 0 0 v3-v4 0 0 0 0 0 v4-v5 0 0 0 0 0 v5-v6 0 0 0 0 0 Jarak numeric \u00b6 def chordDist ( v1 , v2 , jnis ): jmlh = 0 normv1 = 0 normv2 = 0 for x in range ( len ( jnis )): normv1 = normv1 + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) normv2 = normv2 + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) jmlh = jmlh + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) * int ( k . values . tolist ()[ v2 ][ jnis [ x ]])) return (( 2 - ( 2 * jmlh / ( normv1 * normv2 ))) ** 0.5 ) from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 1 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v1-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v2-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 1 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v3-v4\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v4-v5\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 3 , 4 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v5-v6\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' ))) Data Jarak Numeric Ordinal Categorical Binary v1-v2 0 1.41 0 0 0 v1-v3 0 1.41 0 0 0 v2-v3 0 1.41 0 0 0 v3-v4 0 1.41 0 0 0 v4-v5 0 1.41 0 0 0 v5-v6 0 1.41 0 0 0 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Mengukur jarak data"},{"location":"jrak/#mengukur-jarak-data","text":"","title":"Mengukur Jarak Data"},{"location":"jrak/#mengukur-jarak-tipe-numerik","text":"Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkanSebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaitu v1,v2v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn,v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yixi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya","title":"Mengukur Jarak Tipe Numerik"},{"location":"jrak/#minkowski-distance","text":"Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$","title":"Minkowski Distance"},{"location":"jrak/#manhattan-distance","text":"Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$","title":"Manhattan distance"},{"location":"jrak/#euclidean-distance","text":"Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini.","title":"Euclidean distance"},{"location":"jrak/#average-distance","text":"Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik x,y dalam ruang dimensi n, rata-rata jarak didefinisikan dengan $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$","title":"Average Distance"},{"location":"jrak/#weighted-euclidean-distance","text":"Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$","title":"Weighted euclidean distance"},{"location":"jrak/#chord-distance","text":"Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ $$ dimana | x | {2} adalah L^{2} \\text {-norm} | x | {2} = \\sqrt { \\sum_{ i = 1 }^{ n }x_{i}^{2}} $$","title":"Chord distance"},{"location":"jrak/#mahalanobis-distance","text":"Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$","title":"Mahalanobis distance"},{"location":"jrak/#tugas-ii-mengukur-jarak-data","text":"from scipy import stats import numpy as np import seaborn as sns import matplotlib.pyplot as plt import pandas as pd df = pd . read_csv ( 'data2.csv' , sep = \";\" ) k = df . iloc [ 10 : 17 ] k .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age of patient at time of operation Patient's year of operation Number of positive axillary nodes detected Unnamed: 3 10 34 60 1 1 11 34 61 10 1 12 34 67 7 1 13 34 60 0 1 14 35 64 13 1 15 35 63 0 1 16 36 60 1 1 numerical = [ 0 , 3 ] categorical = [ 1 , 2 , 6 , 7 ] binary = [ 4 , 5 , 8 ] ordinal = [ 1 , 2 ] from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v1-v3\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v2-v3\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v3-v4\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v4-v5\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v5-v6\" ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] + [ 0 ] ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' ))) Data Jarak Numeric Ordinal Categorical Binary v1-v2 0 0 0 0 0 v1-v3 0 0 0 0 0 v2-v3 0 0 0 0 0 v3-v4 0 0 0 0 0 v4-v5 0 0 0 0 0 v5-v6 0 0 0 0 0","title":"Tugas II Mengukur Jarak Data"},{"location":"jrak/#jarak-numeric","text":"def chordDist ( v1 , v2 , jnis ): jmlh = 0 normv1 = 0 normv2 = 0 for x in range ( len ( jnis )): normv1 = normv1 + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) normv2 = normv2 + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) ** 2 ) jmlh = jmlh + ( int ( k . values . tolist ()[ v1 ][ jnis [ x ]]) * int ( k . values . tolist ()[ v2 ][ jnis [ x ]])) return (( 2 - ( 2 * jmlh / ( normv1 * normv2 ))) ** 0.5 ) from IPython.display import HTML , display import tabulate table = [ [ \"Data\" ] + [ \"Jarak\" ] + [ \"Numeric\" ] + [ \"Ordinal\" ] + [ \"Categorical\" ] + [ \"Binary\" ], [ \"v1-v2\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 1 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v1-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 0 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v2-v3\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 1 , 2 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v3-v4\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v4-v5\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 3 , 4 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], [ \"v5-v6\" ] + [ 0 ] + [ \"{:.2f}\" . format ( chordDist ( 2 , 3 , numerical ))] + [ 0 ] + [ 0 ] + [ 0 ], ] display ( HTML ( tabulate . tabulate ( table , tablefmt = 'html' ))) Data Jarak Numeric Ordinal Categorical Binary v1-v2 0 1.41 0 0 0 v1-v3 0 1.41 0 0 0 v2-v3 0 1.41 0 0 0 v3-v4 0 1.41 0 0 0 v4-v5 0 1.41 0 0 0 v5-v6 0 1.41 0 0 0 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Jarak numeric"},{"location":"selection/","text":"Feature Selection \u00b6 feature selection atau seleksi fitur adalah sebuah proses yang biasa digunakan pada Machine Learning dimana sekumpulan dari fitur yang dimiliki oleh data digunakan untuk pembelajaran algoritma. Feature selection menurut Oded maimon telah menjadi bidang penelitian aktif dalam pengenalan pola, statistik, dan Data mining. Ide utama dari Feature selection adalah memilih subset dari fitur yang ada tanda transformasi karena tidak semua fitur /atribut relevan dengan masalah. Bahkan beberapa dari fitur atau atribut tersebut mengganggu dan mengurangi akurasi. Noisy Features atau fitur yang tidak terpakai tersebut harus dihapus untuk meningkatkan akurasi. Selain itu dengan fitur atau atribut yang sangat banyak akan memperlambat proses komputasi. Program Feature Selection \u00b6 from pandas import * from IPython.display import HTML , display from tabulate import tabulate from math import log from sklearn.feature_selection import mutual_info_classif def table ( df ): display ( HTML ( tabulate ( df , tablefmt = 'html' , headers = 'keys' , showindex = False ))) df = read_csv ( 'data_layla.csv' , usecols = [ 0 , 1 , 2 , 3 , 4 ], sep = ';' ) table ( df ) dibawah ini merupakan Hasil dari beberapa sampel yang telah ditentukan sebelumnya. outlook temperature humidity windy play sunny hot high False no sunny hot high True no overcast hot high False yes rainy mild high False yes rainy cool normal False yes rainy cool normal True no overcast cool normal True yes sunny mild high False no sunny cool normal False yes rainy mild normal False yes sunny mild normal True yes overcast mild high True yes overcast hot normal False yes rainy mild high True no Entropy \u00b6 Entropy adalah sebuah kolom yang mengandung niali-nilai bersih dari sebuah banyaknya kolom, entropy ini biasanya merupakan kolom yang mewakili pernyataan-pernyataan dari semua kolom . Rumus : $$ E(T) = \\sum_{i=1}^n {-P_i\\log{P_i}} $$ $$ P = merupakan~ probability~ yang ~mucul~ dalam ~row $$ def findEntropy ( column ): rawGroups = df . groupby ( column ) targetGroups = [[ key , len ( data ), len ( data ) / df [ column ] . size ] for key , data in rawGroups ] targetGroups = DataFrame ( targetGroups , columns = [ 'value' , 'count' , 'probability' ]) return sum ([ - x * log ( x , 2 ) for x in targetGroups [ 'probability' ]]), targetGroups , rawGroups entropyTarget , groupTargets , _ = findEntropy ( 'play' ) table ( groupTargets ) print ( 'entropy target =' , entropyTarget ) Tabel entropy yang sudah dicari sebelumnya value count probability no 5 0.357143 yes 9 0.642857 Hasil entropy entropy target = 0.9402859586706309 Gain \u00b6 Merupakan sebuah fitur yang berada dalam sebuah data Rumus mencari Gian \u00b6 $$ \\operatorname{Gain}(T, X) = \\operatorname{Entropy}(T) - \\sum_{v\\in{T}} \\frac{T_{X,v}}{T} E(T_{X,v}) $$ Program \u00b6 def findGain ( column ): entropyOutlook , groupOutlooks , rawOutlooks = findEntropy ( column ) table ( groupOutlooks ) gain = entropyTarget - sum ( len ( data ) / len ( df ) * sum ( - x / len ( data ) * log ( x / len ( data ), 2 ) for x in data . groupby ( 'play' ) . size ()) for key , data in rawOutlooks ) print ( \"gain of\" , column , \"is\" , gain ) return gain gains = [[ x , findGain ( x )] for x in [ 'outlook' , 'temperature' , 'humidity' , 'windy' ]] Outlook \u00b6 value count probability overcast 4 0.285714 rainy 5 0.357143 sunny 5 0.357143 gain of outlook is 0.2467498197744391 Temperature \u00b6 value count probability cool 4 0.285714 hot 4 0.285714 mild 6 0.428571 gain of temperature is 0.029222565658954647 Humidity \u00b6 value count probability high 7 0.5 normal 7 0.5 gain of humidity is 0.15183550136234136 Windy \u00b6 value count probability False 8 0.571429 True 6 0.428571 gain of windy is 0.04812703040826927 Program menyatukan semua Gain: \u00b6 table ( DataFrame ( gains , columns = [ \"Feature\" , \"Gain Score\" ]) . sort_values ( \"Gain Score\" )[:: - 1 ]) Feature Gain Score outlook 0.24675 humidity 0.151836 windy 0.048127 temperature 0.0292226 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"feature selection"},{"location":"selection/#feature-selection","text":"feature selection atau seleksi fitur adalah sebuah proses yang biasa digunakan pada Machine Learning dimana sekumpulan dari fitur yang dimiliki oleh data digunakan untuk pembelajaran algoritma. Feature selection menurut Oded maimon telah menjadi bidang penelitian aktif dalam pengenalan pola, statistik, dan Data mining. Ide utama dari Feature selection adalah memilih subset dari fitur yang ada tanda transformasi karena tidak semua fitur /atribut relevan dengan masalah. Bahkan beberapa dari fitur atau atribut tersebut mengganggu dan mengurangi akurasi. Noisy Features atau fitur yang tidak terpakai tersebut harus dihapus untuk meningkatkan akurasi. Selain itu dengan fitur atau atribut yang sangat banyak akan memperlambat proses komputasi.","title":"Feature Selection"},{"location":"selection/#program-feature-selection","text":"from pandas import * from IPython.display import HTML , display from tabulate import tabulate from math import log from sklearn.feature_selection import mutual_info_classif def table ( df ): display ( HTML ( tabulate ( df , tablefmt = 'html' , headers = 'keys' , showindex = False ))) df = read_csv ( 'data_layla.csv' , usecols = [ 0 , 1 , 2 , 3 , 4 ], sep = ';' ) table ( df ) dibawah ini merupakan Hasil dari beberapa sampel yang telah ditentukan sebelumnya. outlook temperature humidity windy play sunny hot high False no sunny hot high True no overcast hot high False yes rainy mild high False yes rainy cool normal False yes rainy cool normal True no overcast cool normal True yes sunny mild high False no sunny cool normal False yes rainy mild normal False yes sunny mild normal True yes overcast mild high True yes overcast hot normal False yes rainy mild high True no","title":"Program Feature Selection"},{"location":"selection/#entropy","text":"Entropy adalah sebuah kolom yang mengandung niali-nilai bersih dari sebuah banyaknya kolom, entropy ini biasanya merupakan kolom yang mewakili pernyataan-pernyataan dari semua kolom . Rumus : $$ E(T) = \\sum_{i=1}^n {-P_i\\log{P_i}} $$ $$ P = merupakan~ probability~ yang ~mucul~ dalam ~row $$ def findEntropy ( column ): rawGroups = df . groupby ( column ) targetGroups = [[ key , len ( data ), len ( data ) / df [ column ] . size ] for key , data in rawGroups ] targetGroups = DataFrame ( targetGroups , columns = [ 'value' , 'count' , 'probability' ]) return sum ([ - x * log ( x , 2 ) for x in targetGroups [ 'probability' ]]), targetGroups , rawGroups entropyTarget , groupTargets , _ = findEntropy ( 'play' ) table ( groupTargets ) print ( 'entropy target =' , entropyTarget ) Tabel entropy yang sudah dicari sebelumnya value count probability no 5 0.357143 yes 9 0.642857 Hasil entropy entropy target = 0.9402859586706309","title":"Entropy"},{"location":"selection/#gain","text":"Merupakan sebuah fitur yang berada dalam sebuah data","title":"Gain"},{"location":"selection/#rumus-mencari-gian","text":"$$ \\operatorname{Gain}(T, X) = \\operatorname{Entropy}(T) - \\sum_{v\\in{T}} \\frac{T_{X,v}}{T} E(T_{X,v}) $$","title":"Rumus mencari Gian"},{"location":"selection/#program","text":"def findGain ( column ): entropyOutlook , groupOutlooks , rawOutlooks = findEntropy ( column ) table ( groupOutlooks ) gain = entropyTarget - sum ( len ( data ) / len ( df ) * sum ( - x / len ( data ) * log ( x / len ( data ), 2 ) for x in data . groupby ( 'play' ) . size ()) for key , data in rawOutlooks ) print ( \"gain of\" , column , \"is\" , gain ) return gain gains = [[ x , findGain ( x )] for x in [ 'outlook' , 'temperature' , 'humidity' , 'windy' ]]","title":"Program"},{"location":"selection/#outlook","text":"value count probability overcast 4 0.285714 rainy 5 0.357143 sunny 5 0.357143 gain of outlook is 0.2467498197744391","title":"Outlook"},{"location":"selection/#temperature","text":"value count probability cool 4 0.285714 hot 4 0.285714 mild 6 0.428571 gain of temperature is 0.029222565658954647","title":"Temperature"},{"location":"selection/#humidity","text":"value count probability high 7 0.5 normal 7 0.5 gain of humidity is 0.15183550136234136","title":"Humidity"},{"location":"selection/#windy","text":"value count probability False 8 0.571429 True 6 0.428571 gain of windy is 0.04812703040826927","title":"Windy"},{"location":"selection/#program-menyatukan-semua-gain","text":"table ( DataFrame ( gains , columns = [ \"Feature\" , \"Gain Score\" ]) . sort_values ( \"Gain Score\" )[:: - 1 ]) Feature Gain Score outlook 0.24675 humidity 0.151836 windy 0.048127 temperature 0.0292226 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Program menyatukan semua Gain:"},{"location":"tugas1/","text":"Mean, Modus dan Median \u00b6 Rumus Mean (Rata-rata) Data Kelompok \u00b6 Untuk dapat menentukan mean atau rata rata dari data kelompok maka kita perlu menjumlahkan semua data kemudian membaginya dengan banyaknya data tersebut.namun, karena penyajian data kelompok tersebut diberikan dalam bentuk yang berbeda, maka rumus untuk mencari nilai mean (rata rata) untuk data kelompok itu terlihat sedikit berbeda dengan cara mencari nilai mean (rata rata) pada data tunggal. Rumus mean data kelompok dinyatakan dengan persamaan seperti di bawah. $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Rumus Median Data Kelompok \u00b6 Median ialah data tengah setelah diurutkan. Pada data tunggal, nilai median tersebut dapat dicari dengan mengurutkan datanya terlebih dahulu kemudian mencari data yang terletak tepat di tengahnya.cara ini Hampir sama dengan cara mencari median pada data tunggal, nilai median pada data kelompok juga merupakan nilai tengah dari suatu kumpulan data. Karena bentuk penyajian datanya disajikan dalam bentuk kelompok,maka datanya tidak dapat diurutkan seperti pada data tunggal. Dengan demikian, agar dapat mencari nilai median dari suatu data kelompok diperlukan sebuah rumus. Rumus median data kelompok ialah sebagai berikut. $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ Rumus Modus Data Kelompok \u00b6 Modus ialah nilai data yang paling sering muncul atau data yang memiliki nilai frekuensi paling tinggi.untuk mencari nilai modus pada data tunggal sangat mudah,yaitu dengan Cara mencari nilai data dengan frekuensi paling banyak.namun untuk mencari mencari nilai modus pada data kelompok tidak lah semudah kita mencari nilai modus pada data tunggal. Hal ini dikarenakan bentuk penyajian data kelompok yang disajikan dalam sebuah rentang kelas. Sehingga, nilai modus data kelompok tidak mudah untuk langsung didapatkan dan untuk menemukan nilai modus dari data kelompok maka kita perlu menggunakan sebuah rumus. Rumus modus data kelompok dapat dilihat seperti persamaan di bawah ini. $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Variansi dan Standar Deviasi \u00b6 Variansi dan standar deviasi adalah ukuran penyebaran data. Nilai-nilai tersebut menunjukkan bagaimana penyebaran distribusi data. Standar Deviasi yang rendah berarti bahwa pengamatan data cenderung sangat dekat dengan rata-rata, sedangkan deviasi standar yang tinggi menunjukkan data tersebar di sejumlah nilai-nilai besar. Varian dari pengamatan N,x1,x2,...,xN, untuk atribut numerik X adalah $$ \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } $$ Skewness \u00b6 Derajat distorsi dari kurva lonceng simetris atau distribusi normal. Ini mengukur kurangnya simetri dalam distribusi data Untuk menghitung derajat distorisi dapat menggunakan Koefisien Kemencengan Pearson yang diperoleh dengan menggunakan nilai selisih rata-rata dengan modus dibagi simpangan baku. Koefisien Kemencengan Pearson dirumuskan sebagai berikut $$ s k=\\frac{\\overline{X}-M o}{s} $$ dengan $$ \\overline{X}-M o \\approx 3(\\overline{X}-M e) $$ maka $$ s k \\approx \\frac{3(\\overline{X}-M e)}{s} $$ Tugas import pandas as pd from scipy import stats df = pd . read_csv ( 'data.csv' , sep = \";\" ) data = { \"stats\" :[ 'min' , 'max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . mean (), stats . mode ( df [ i ]) . mode [ 0 ]] kd = pd . DataFrame ( data ) kd . style . hide_index () MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Statistik deskriptif"},{"location":"tugas1/#mean-modus-dan-median","text":"","title":"Mean, Modus dan Median"},{"location":"tugas1/#rumus-mean-rata-rata-data-kelompok","text":"Untuk dapat menentukan mean atau rata rata dari data kelompok maka kita perlu menjumlahkan semua data kemudian membaginya dengan banyaknya data tersebut.namun, karena penyajian data kelompok tersebut diberikan dalam bentuk yang berbeda, maka rumus untuk mencari nilai mean (rata rata) untuk data kelompok itu terlihat sedikit berbeda dengan cara mencari nilai mean (rata rata) pada data tunggal. Rumus mean data kelompok dinyatakan dengan persamaan seperti di bawah. $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$","title":"Rumus Mean (Rata-rata) Data Kelompok"},{"location":"tugas1/#rumus-median-data-kelompok","text":"Median ialah data tengah setelah diurutkan. Pada data tunggal, nilai median tersebut dapat dicari dengan mengurutkan datanya terlebih dahulu kemudian mencari data yang terletak tepat di tengahnya.cara ini Hampir sama dengan cara mencari median pada data tunggal, nilai median pada data kelompok juga merupakan nilai tengah dari suatu kumpulan data. Karena bentuk penyajian datanya disajikan dalam bentuk kelompok,maka datanya tidak dapat diurutkan seperti pada data tunggal. Dengan demikian, agar dapat mencari nilai median dari suatu data kelompok diperlukan sebuah rumus. Rumus median data kelompok ialah sebagai berikut. $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$","title":"Rumus Median Data Kelompok"},{"location":"tugas1/#rumus-modus-data-kelompok","text":"Modus ialah nilai data yang paling sering muncul atau data yang memiliki nilai frekuensi paling tinggi.untuk mencari nilai modus pada data tunggal sangat mudah,yaitu dengan Cara mencari nilai data dengan frekuensi paling banyak.namun untuk mencari mencari nilai modus pada data kelompok tidak lah semudah kita mencari nilai modus pada data tunggal. Hal ini dikarenakan bentuk penyajian data kelompok yang disajikan dalam sebuah rentang kelas. Sehingga, nilai modus data kelompok tidak mudah untuk langsung didapatkan dan untuk menemukan nilai modus dari data kelompok maka kita perlu menggunakan sebuah rumus. Rumus modus data kelompok dapat dilihat seperti persamaan di bawah ini. $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$","title":"Rumus Modus Data Kelompok"},{"location":"tugas1/#variansi-dan-standar-deviasi","text":"Variansi dan standar deviasi adalah ukuran penyebaran data. Nilai-nilai tersebut menunjukkan bagaimana penyebaran distribusi data. Standar Deviasi yang rendah berarti bahwa pengamatan data cenderung sangat dekat dengan rata-rata, sedangkan deviasi standar yang tinggi menunjukkan data tersebar di sejumlah nilai-nilai besar. Varian dari pengamatan N,x1,x2,...,xN, untuk atribut numerik X adalah $$ \\sigma ^ { 2 } = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( x _ { i } - \\overline { x } ) ^ { 2 } = ( \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \\overline { x } ^ { 2 } $$","title":"Variansi dan Standar Deviasi"},{"location":"tugas1/#skewness","text":"Derajat distorsi dari kurva lonceng simetris atau distribusi normal. Ini mengukur kurangnya simetri dalam distribusi data Untuk menghitung derajat distorisi dapat menggunakan Koefisien Kemencengan Pearson yang diperoleh dengan menggunakan nilai selisih rata-rata dengan modus dibagi simpangan baku. Koefisien Kemencengan Pearson dirumuskan sebagai berikut $$ s k=\\frac{\\overline{X}-M o}{s} $$ dengan $$ \\overline{X}-M o \\approx 3(\\overline{X}-M e) $$ maka $$ s k \\approx \\frac{3(\\overline{X}-M e)}{s} $$ Tugas import pandas as pd from scipy import stats df = pd . read_csv ( 'data.csv' , sep = \";\" ) data = { \"stats\" :[ 'min' , 'max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . mean (), stats . mode ( df [ i ]) . mode [ 0 ]] kd = pd . DataFrame ( data ) kd . style . hide_index () MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Skewness"}]}